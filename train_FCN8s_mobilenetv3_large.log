04/11/2022 11:15:46 AM - WARNING - From E:/pycharm_project/segmentation_project/train.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

04/11/2022 11:15:46 AM - WARNING - From E:\pycharm_project\segmentation_project\model\FCN8s.py:9: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

04/11/2022 11:15:46 AM - WARNING - From E:\pycharm_project\segmentation_project\model\backend_layers.py:6: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

04/11/2022 11:15:46 AM - WARNING - 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

04/11/2022 11:15:46 AM - WARNING - From E:\pycharm_project\segmentation_project\model\backend_layers.py:13: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

04/11/2022 11:15:46 AM - WARNING - From E:\pycharm_project\segmentation_project\model\backend_layers.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

04/11/2022 11:15:46 AM - WARNING - From E:\pycharm_project\segmentation_project\model\backend_layers.py:80: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).
04/11/2022 11:15:46 AM - WARNING - From E:\Anaconda\envs\tf115\lib\site-packages\tensorflow_core\python\layers\normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
04/11/2022 11:15:47 AM - WARNING - From E:\pycharm_project\segmentation_project\model\backend_layers.py:190: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

04/11/2022 11:15:47 AM - WARNING - From E:/pycharm_project/segmentation_project/train.py:48: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

04/11/2022 11:15:47 AM - WARNING - From E:/pycharm_project/segmentation_project/train.py:52: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

04/11/2022 11:15:47 AM - WARNING - From E:/pycharm_project/segmentation_project/train.py:56: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

04/11/2022 11:15:49 AM - WARNING - From E:/pycharm_project/segmentation_project/train.py:61: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

04/11/2022 11:15:49 AM - WARNING - From E:/pycharm_project/segmentation_project/train.py:67: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

04/11/2022 11:15:49 AM - WARNING - From E:/pycharm_project/segmentation_project/train.py:73: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

04/11/2022 11:15:50 AM - WARNING - From E:/pycharm_project/segmentation_project/train.py:80: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

04/11/2022 11:15:50 AM - WARNING - From E:/pycharm_project/segmentation_project/train.py:83: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

04/11/2022 11:15:50 AM - WARNING - From E:/pycharm_project/segmentation_project/train.py:87: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

04/11/2022 11:16:00 AM - INFO - => Restoring backbone weights from: E:\pycharm_project\segmentation_project\checkpoints\pretrained_backbones\mobilenetv3_add_prefix.ckpt ... 
04/11/2022 11:16:00 AM - INFO - Restoring parameters from E:\pycharm_project\segmentation_project\checkpoints\pretrained_backbones\mobilenetv3_add_prefix.ckpt
04/11/2022 11:16:01 AM - INFO - ========================================================================================
04/11/2022 11:16:01 AM - INFO - LIST ALL TRAINABLE VARIABLES
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/head_conv1/weights:0  shape: (3, 3, 3, 16)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/head_conv1/bn/gamma:0  shape: (16,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/head_conv1/bn/beta:0  shape: (16,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/head_dwconv/weights:0  shape: (3, 3, 16, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/head_dwconv/bn/gamma:0  shape: (16,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/head_dwconv/bn/beta:0  shape: (16,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/head_conv2/weights:0  shape: (1, 1, 16, 16)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/head_conv2/bn/gamma:0  shape: (16,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/head_conv2/bn/beta:0  shape: (16,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_1/expand_conv/weights:0  shape: (1, 1, 16, 64)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_1/expand_conv/bn/gamma:0  shape: (64,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_1/expand_conv/bn/beta:0  shape: (64,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_1/dp_conv/weights:0  shape: (3, 3, 64, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_1/dp_conv/bn/gamma:0  shape: (64,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_1/dp_conv/bn/beta:0  shape: (64,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_1/proj_conv/weights:0  shape: (1, 1, 64, 24)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_1/proj_conv/bn/gamma:0  shape: (24,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_1/proj_conv/bn/beta:0  shape: (24,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_2/expand_conv/weights:0  shape: (1, 1, 24, 72)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_2/expand_conv/bn/gamma:0  shape: (72,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_2/expand_conv/bn/beta:0  shape: (72,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_2/dp_conv/weights:0  shape: (3, 3, 72, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_2/dp_conv/bn/gamma:0  shape: (72,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_2/dp_conv/bn/beta:0  shape: (72,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_2/proj_conv/weights:0  shape: (1, 1, 72, 24)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_2/proj_conv/bn/gamma:0  shape: (24,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck1_2/proj_conv/bn/beta:0  shape: (24,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/expand_conv/weights:0  shape: (1, 1, 24, 72)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/expand_conv/bn/gamma:0  shape: (72,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/expand_conv/bn/beta:0  shape: (72,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/dp_conv/weights:0  shape: (5, 5, 72, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/dp_conv/bn/gamma:0  shape: (72,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/dp_conv/bn/beta:0  shape: (72,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/SEmodule/dense1/conv/weights:0  shape: (1, 1, 72, 24)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/SEmodule/dense1/conv/bias:0  shape: (24,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/SEmodule/dense2/conv/weights:0  shape: (1, 1, 24, 72)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/SEmodule/dense2/conv/bias:0  shape: (72,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/proj_conv/weights:0  shape: (1, 1, 72, 40)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/proj_conv/bn/gamma:0  shape: (40,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_1/proj_conv/bn/beta:0  shape: (40,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/expand_conv/weights:0  shape: (1, 1, 40, 120)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/expand_conv/bn/gamma:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/expand_conv/bn/beta:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/dp_conv/weights:0  shape: (5, 5, 120, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/dp_conv/bn/gamma:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/dp_conv/bn/beta:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/SEmodule/dense1/conv/weights:0  shape: (1, 1, 120, 32)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/SEmodule/dense1/conv/bias:0  shape: (32,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/SEmodule/dense2/conv/weights:0  shape: (1, 1, 32, 120)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/SEmodule/dense2/conv/bias:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/proj_conv/weights:0  shape: (1, 1, 120, 40)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/proj_conv/bn/gamma:0  shape: (40,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_2/proj_conv/bn/beta:0  shape: (40,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/expand_conv/weights:0  shape: (1, 1, 40, 120)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/expand_conv/bn/gamma:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/expand_conv/bn/beta:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/dp_conv/weights:0  shape: (5, 5, 120, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/dp_conv/bn/gamma:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/dp_conv/bn/beta:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/SEmodule/dense1/conv/weights:0  shape: (1, 1, 120, 32)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/SEmodule/dense1/conv/bias:0  shape: (32,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/SEmodule/dense2/conv/weights:0  shape: (1, 1, 32, 120)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/SEmodule/dense2/conv/bias:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/proj_conv/weights:0  shape: (1, 1, 120, 40)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/proj_conv/bn/gamma:0  shape: (40,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck2_3/proj_conv/bn/beta:0  shape: (40,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_1/expand_conv/weights:0  shape: (1, 1, 40, 240)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_1/expand_conv/bn/gamma:0  shape: (240,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_1/expand_conv/bn/beta:0  shape: (240,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_1/dp_conv/weights:0  shape: (3, 3, 240, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_1/dp_conv/bn/gamma:0  shape: (240,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_1/dp_conv/bn/beta:0  shape: (240,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_1/proj_conv/weights:0  shape: (1, 1, 240, 80)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_1/proj_conv/bn/gamma:0  shape: (80,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_1/proj_conv/bn/beta:0  shape: (80,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_2/expand_conv/weights:0  shape: (1, 1, 80, 200)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_2/expand_conv/bn/gamma:0  shape: (200,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_2/expand_conv/bn/beta:0  shape: (200,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_2/dp_conv/weights:0  shape: (3, 3, 200, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_2/dp_conv/bn/gamma:0  shape: (200,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_2/dp_conv/bn/beta:0  shape: (200,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_2/proj_conv/weights:0  shape: (1, 1, 200, 80)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_2/proj_conv/bn/gamma:0  shape: (80,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_2/proj_conv/bn/beta:0  shape: (80,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_3/expand_conv/weights:0  shape: (1, 1, 80, 184)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_3/expand_conv/bn/gamma:0  shape: (184,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_3/expand_conv/bn/beta:0  shape: (184,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_3/dp_conv/weights:0  shape: (3, 3, 184, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_3/dp_conv/bn/gamma:0  shape: (184,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_3/dp_conv/bn/beta:0  shape: (184,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_3/proj_conv/weights:0  shape: (1, 1, 184, 80)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_3/proj_conv/bn/gamma:0  shape: (80,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_3/proj_conv/bn/beta:0  shape: (80,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_4/expand_conv/weights:0  shape: (1, 1, 80, 184)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_4/expand_conv/bn/gamma:0  shape: (184,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_4/expand_conv/bn/beta:0  shape: (184,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_4/dp_conv/weights:0  shape: (3, 3, 184, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_4/dp_conv/bn/gamma:0  shape: (184,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_4/dp_conv/bn/beta:0  shape: (184,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_4/proj_conv/weights:0  shape: (1, 1, 184, 80)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_4/proj_conv/bn/gamma:0  shape: (80,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_4/proj_conv/bn/beta:0  shape: (80,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/expand_conv/weights:0  shape: (1, 1, 80, 480)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/expand_conv/bn/gamma:0  shape: (480,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/expand_conv/bn/beta:0  shape: (480,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/dp_conv/weights:0  shape: (3, 3, 480, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/dp_conv/bn/gamma:0  shape: (480,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/dp_conv/bn/beta:0  shape: (480,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/SEmodule/dense1/conv/weights:0  shape: (1, 1, 480, 120)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/SEmodule/dense1/conv/bias:0  shape: (120,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/SEmodule/dense2/conv/weights:0  shape: (1, 1, 120, 480)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/SEmodule/dense2/conv/bias:0  shape: (480,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/proj_conv/weights:0  shape: (1, 1, 480, 112)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/proj_conv/bn/gamma:0  shape: (112,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_5/proj_conv/bn/beta:0  shape: (112,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/expand_conv/weights:0  shape: (1, 1, 112, 672)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/expand_conv/bn/gamma:0  shape: (672,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/expand_conv/bn/beta:0  shape: (672,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/dp_conv/weights:0  shape: (3, 3, 672, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/dp_conv/bn/gamma:0  shape: (672,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/dp_conv/bn/beta:0  shape: (672,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/SEmodule/dense1/conv/weights:0  shape: (1, 1, 672, 168)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/SEmodule/dense1/conv/bias:0  shape: (168,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/SEmodule/dense2/conv/weights:0  shape: (1, 1, 168, 672)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/SEmodule/dense2/conv/bias:0  shape: (672,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/proj_conv/weights:0  shape: (1, 1, 672, 112)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/proj_conv/bn/gamma:0  shape: (112,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck3_6/proj_conv/bn/beta:0  shape: (112,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/expand_conv/weights:0  shape: (1, 1, 112, 672)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/expand_conv/bn/gamma:0  shape: (672,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/expand_conv/bn/beta:0  shape: (672,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/dp_conv/weights:0  shape: (5, 5, 672, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/dp_conv/bn/gamma:0  shape: (672,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/dp_conv/bn/beta:0  shape: (672,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/SEmodule/dense1/conv/weights:0  shape: (1, 1, 672, 168)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/SEmodule/dense1/conv/bias:0  shape: (168,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/SEmodule/dense2/conv/weights:0  shape: (1, 1, 168, 672)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/SEmodule/dense2/conv/bias:0  shape: (672,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/proj_conv/weights:0  shape: (1, 1, 672, 160)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/proj_conv/bn/gamma:0  shape: (160,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_1/proj_conv/bn/beta:0  shape: (160,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/expand_conv/weights:0  shape: (1, 1, 160, 960)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/expand_conv/bn/gamma:0  shape: (960,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/expand_conv/bn/beta:0  shape: (960,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/dp_conv/weights:0  shape: (5, 5, 960, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/dp_conv/bn/gamma:0  shape: (960,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/dp_conv/bn/beta:0  shape: (960,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/SEmodule/dense1/conv/weights:0  shape: (1, 1, 960, 240)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/SEmodule/dense1/conv/bias:0  shape: (240,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/SEmodule/dense2/conv/weights:0  shape: (1, 1, 240, 960)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/SEmodule/dense2/conv/bias:0  shape: (960,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/proj_conv/weights:0  shape: (1, 1, 960, 160)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/proj_conv/bn/gamma:0  shape: (160,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_2/proj_conv/bn/beta:0  shape: (160,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/expand_conv/weights:0  shape: (1, 1, 160, 960)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/expand_conv/bn/gamma:0  shape: (960,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/expand_conv/bn/beta:0  shape: (960,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/dp_conv/weights:0  shape: (5, 5, 960, 1)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/dp_conv/bn/gamma:0  shape: (960,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/dp_conv/bn/beta:0  shape: (960,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/SEmodule/dense1/conv/weights:0  shape: (1, 1, 960, 240)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/SEmodule/dense1/conv/bias:0  shape: (240,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/SEmodule/dense2/conv/weights:0  shape: (1, 1, 240, 960)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/SEmodule/dense2/conv/bias:0  shape: (960,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/proj_conv/weights:0  shape: (1, 1, 960, 160)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/proj_conv/bn/gamma:0  shape: (160,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/encoder/mobilenetv3_large/bottleneck4_3/proj_conv/bn/beta:0  shape: (160,)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/decoder/scores_32s/weights:0  shape: (1, 1, 160, 3)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/decoder/scores_16s/weights:0  shape: (1, 1, 112, 3)
04/11/2022 11:16:01 AM - INFO - name: FCN8s/decoder/scores_8s/weights:0  shape: (1, 1, 40, 3)
04/11/2022 11:16:01 AM - INFO - ========================================================================================
04/11/2022 11:16:09 AM - INFO - global step: 10, epoch_1, lr: 0.00100, 10/519: Train average loss: 2.021
04/11/2022 11:16:13 AM - INFO - global step: 20, epoch_1, lr: 0.00100, 20/519: Train average loss: 1.599
04/11/2022 11:16:18 AM - INFO - global step: 30, epoch_1, lr: 0.00100, 30/519: Train average loss: 1.334
04/11/2022 11:16:22 AM - INFO - global step: 40, epoch_1, lr: 0.00100, 40/519: Train average loss: 1.156
04/11/2022 11:16:26 AM - INFO - global step: 50, epoch_1, lr: 0.00100, 50/519: Train average loss: 1.046
04/11/2022 11:16:31 AM - INFO - global step: 60, epoch_1, lr: 0.00100, 60/519: Train average loss: 0.975
04/11/2022 11:16:35 AM - INFO - global step: 70, epoch_1, lr: 0.00100, 70/519: Train average loss: 0.918
04/11/2022 11:16:39 AM - INFO - global step: 80, epoch_1, lr: 0.00100, 80/519: Train average loss: 0.878
04/11/2022 11:16:43 AM - INFO - global step: 90, epoch_1, lr: 0.00100, 90/519: Train average loss: 0.842
04/11/2022 11:16:48 AM - INFO - global step: 100, epoch_1, lr: 0.00100, 100/519: Train average loss: 0.811
04/11/2022 11:16:52 AM - INFO - global step: 110, epoch_1, lr: 0.00100, 110/519: Train average loss: 0.782
04/11/2022 11:16:56 AM - INFO - global step: 120, epoch_1, lr: 0.00100, 120/519: Train average loss: 0.763
04/11/2022 11:17:00 AM - INFO - global step: 130, epoch_1, lr: 0.00100, 130/519: Train average loss: 0.743
04/11/2022 11:17:05 AM - INFO - global step: 140, epoch_1, lr: 0.00100, 140/519: Train average loss: 0.728
04/11/2022 11:17:09 AM - INFO - global step: 150, epoch_1, lr: 0.00100, 150/519: Train average loss: 0.715
04/11/2022 11:17:13 AM - INFO - global step: 160, epoch_1, lr: 0.00100, 160/519: Train average loss: 0.701
04/11/2022 11:17:17 AM - INFO - global step: 170, epoch_1, lr: 0.00100, 170/519: Train average loss: 0.688
04/11/2022 11:17:21 AM - INFO - global step: 180, epoch_1, lr: 0.00100, 180/519: Train average loss: 0.675
04/11/2022 11:17:26 AM - INFO - global step: 190, epoch_1, lr: 0.00100, 190/519: Train average loss: 0.664
04/11/2022 11:17:30 AM - INFO - global step: 200, epoch_1, lr: 0.00100, 200/519: Train average loss: 0.653
04/11/2022 11:17:34 AM - INFO - global step: 210, epoch_1, lr: 0.00100, 210/519: Train average loss: 0.644
04/11/2022 11:17:38 AM - INFO - global step: 220, epoch_1, lr: 0.00100, 220/519: Train average loss: 0.635
04/11/2022 11:17:42 AM - INFO - global step: 230, epoch_1, lr: 0.00100, 230/519: Train average loss: 0.626
04/11/2022 11:17:47 AM - INFO - global step: 240, epoch_1, lr: 0.00100, 240/519: Train average loss: 0.620
04/11/2022 11:17:51 AM - INFO - global step: 250, epoch_1, lr: 0.00100, 250/519: Train average loss: 0.613
04/11/2022 11:17:55 AM - INFO - global step: 260, epoch_1, lr: 0.00100, 260/519: Train average loss: 0.606
04/11/2022 11:17:59 AM - INFO - global step: 270, epoch_1, lr: 0.00100, 270/519: Train average loss: 0.601
04/11/2022 11:18:03 AM - INFO - global step: 280, epoch_1, lr: 0.00100, 280/519: Train average loss: 0.596
04/11/2022 11:18:08 AM - INFO - global step: 290, epoch_1, lr: 0.00100, 290/519: Train average loss: 0.590
04/11/2022 11:18:12 AM - INFO - global step: 300, epoch_1, lr: 0.00100, 300/519: Train average loss: 0.585
04/11/2022 11:18:16 AM - INFO - global step: 310, epoch_1, lr: 0.00100, 310/519: Train average loss: 0.582
04/11/2022 11:18:20 AM - INFO - global step: 320, epoch_1, lr: 0.00100, 320/519: Train average loss: 0.578
04/11/2022 11:18:25 AM - INFO - global step: 330, epoch_1, lr: 0.00100, 330/519: Train average loss: 0.573
04/11/2022 11:18:29 AM - INFO - global step: 340, epoch_1, lr: 0.00100, 340/519: Train average loss: 0.568
04/11/2022 11:18:33 AM - INFO - global step: 350, epoch_1, lr: 0.00100, 350/519: Train average loss: 0.564
04/11/2022 11:18:37 AM - INFO - global step: 360, epoch_1, lr: 0.00100, 360/519: Train average loss: 0.560
04/11/2022 11:18:41 AM - INFO - global step: 370, epoch_1, lr: 0.00100, 370/519: Train average loss: 0.558
04/11/2022 11:18:46 AM - INFO - global step: 380, epoch_1, lr: 0.00100, 380/519: Train average loss: 0.555
04/11/2022 11:18:50 AM - INFO - global step: 390, epoch_1, lr: 0.00100, 390/519: Train average loss: 0.551
04/11/2022 11:18:54 AM - INFO - global step: 400, epoch_1, lr: 0.00100, 400/519: Train average loss: 0.549
04/11/2022 11:18:58 AM - INFO - global step: 410, epoch_1, lr: 0.00100, 410/519: Train average loss: 0.545
04/11/2022 11:19:03 AM - INFO - global step: 420, epoch_1, lr: 0.00100, 420/519: Train average loss: 0.542
04/11/2022 11:19:07 AM - INFO - global step: 430, epoch_1, lr: 0.00100, 430/519: Train average loss: 0.540
04/11/2022 11:19:11 AM - INFO - global step: 440, epoch_1, lr: 0.00100, 440/519: Train average loss: 0.537
04/11/2022 11:19:15 AM - INFO - global step: 450, epoch_1, lr: 0.00100, 450/519: Train average loss: 0.536
04/11/2022 11:19:19 AM - INFO - global step: 460, epoch_1, lr: 0.00100, 460/519: Train average loss: 0.534
04/11/2022 11:19:24 AM - INFO - global step: 470, epoch_1, lr: 0.00100, 470/519: Train average loss: 0.531
04/11/2022 11:19:28 AM - INFO - global step: 480, epoch_1, lr: 0.00100, 480/519: Train average loss: 0.528
04/11/2022 11:19:32 AM - INFO - global step: 490, epoch_1, lr: 0.00100, 490/519: Train average loss: 0.525
04/11/2022 11:19:36 AM - INFO - global step: 500, epoch_1, lr: 0.00100, 500/519: Train average loss: 0.522
04/11/2022 11:19:40 AM - INFO - global step: 510, epoch_1, lr: 0.00100, 510/519: Train average loss: 0.520
04/11/2022 11:19:44 AM - INFO - ==========================================================
04/11/2022 11:19:44 AM - INFO - epoch_1: Train set(Aug) miou is: 0.441
04/11/2022 11:19:54 AM - INFO - epoch_1: Valid set average loss is: 0.383
04/11/2022 11:19:54 AM - INFO - epoch_1: Valid set miou is: 0.457
04/11/2022 11:19:54 AM - INFO - ==========================================================
04/11/2022 11:19:58 AM - INFO - global step: 529, epoch_2, lr: 0.00100, 10/519: Train average loss: 0.405
04/11/2022 11:20:03 AM - INFO - global step: 539, epoch_2, lr: 0.00100, 20/519: Train average loss: 0.401
04/11/2022 11:20:08 AM - INFO - global step: 549, epoch_2, lr: 0.00100, 30/519: Train average loss: 0.399
04/11/2022 11:20:13 AM - INFO - global step: 559, epoch_2, lr: 0.00100, 40/519: Train average loss: 0.399
04/11/2022 11:20:17 AM - INFO - global step: 569, epoch_2, lr: 0.00100, 50/519: Train average loss: 0.401
04/11/2022 11:20:22 AM - INFO - global step: 579, epoch_2, lr: 0.00100, 60/519: Train average loss: 0.404
04/11/2022 11:20:26 AM - INFO - global step: 589, epoch_2, lr: 0.00100, 70/519: Train average loss: 0.403
04/11/2022 11:20:31 AM - INFO - global step: 599, epoch_2, lr: 0.00100, 80/519: Train average loss: 0.402
04/11/2022 11:20:35 AM - INFO - global step: 609, epoch_2, lr: 0.00100, 90/519: Train average loss: 0.401
04/11/2022 11:20:40 AM - INFO - global step: 619, epoch_2, lr: 0.00100, 100/519: Train average loss: 0.404
04/11/2022 11:20:45 AM - INFO - global step: 629, epoch_2, lr: 0.00100, 110/519: Train average loss: 0.406
04/11/2022 11:20:49 AM - INFO - global step: 639, epoch_2, lr: 0.00100, 120/519: Train average loss: 0.405
04/11/2022 11:20:54 AM - INFO - global step: 649, epoch_2, lr: 0.00100, 130/519: Train average loss: 0.403
04/11/2022 11:20:58 AM - INFO - global step: 659, epoch_2, lr: 0.00100, 140/519: Train average loss: 0.405
04/11/2022 11:21:03 AM - INFO - global step: 669, epoch_2, lr: 0.00100, 150/519: Train average loss: 0.405
04/11/2022 11:21:07 AM - INFO - global step: 679, epoch_2, lr: 0.00100, 160/519: Train average loss: 0.406
04/11/2022 11:21:12 AM - INFO - global step: 689, epoch_2, lr: 0.00100, 170/519: Train average loss: 0.406
04/11/2022 11:21:16 AM - INFO - global step: 699, epoch_2, lr: 0.00100, 180/519: Train average loss: 0.407
04/11/2022 11:21:20 AM - INFO - global step: 709, epoch_2, lr: 0.00100, 190/519: Train average loss: 0.406
04/11/2022 11:21:25 AM - INFO - global step: 719, epoch_2, lr: 0.00100, 200/519: Train average loss: 0.406
04/11/2022 11:21:29 AM - INFO - global step: 729, epoch_2, lr: 0.00100, 210/519: Train average loss: 0.405
04/11/2022 11:21:34 AM - INFO - global step: 739, epoch_2, lr: 0.00100, 220/519: Train average loss: 0.405
04/11/2022 11:21:38 AM - INFO - global step: 749, epoch_2, lr: 0.00100, 230/519: Train average loss: 0.406
04/11/2022 11:21:42 AM - INFO - global step: 759, epoch_2, lr: 0.00100, 240/519: Train average loss: 0.404
04/11/2022 11:21:47 AM - INFO - global step: 769, epoch_2, lr: 0.00100, 250/519: Train average loss: 0.402
04/11/2022 11:21:51 AM - INFO - global step: 779, epoch_2, lr: 0.00100, 260/519: Train average loss: 0.401
04/11/2022 11:21:55 AM - INFO - global step: 789, epoch_2, lr: 0.00100, 270/519: Train average loss: 0.402
04/11/2022 11:22:00 AM - INFO - global step: 799, epoch_2, lr: 0.00100, 280/519: Train average loss: 0.402
04/11/2022 11:22:04 AM - INFO - global step: 809, epoch_2, lr: 0.00100, 290/519: Train average loss: 0.401
04/11/2022 11:22:09 AM - INFO - global step: 819, epoch_2, lr: 0.00100, 300/519: Train average loss: 0.400
04/11/2022 11:22:13 AM - INFO - global step: 829, epoch_2, lr: 0.00100, 310/519: Train average loss: 0.402
04/11/2022 11:22:17 AM - INFO - global step: 839, epoch_2, lr: 0.00100, 320/519: Train average loss: 0.401
04/11/2022 11:22:22 AM - INFO - global step: 849, epoch_2, lr: 0.00100, 330/519: Train average loss: 0.402
04/11/2022 11:22:26 AM - INFO - global step: 859, epoch_2, lr: 0.00100, 340/519: Train average loss: 0.401
04/11/2022 11:22:31 AM - INFO - global step: 869, epoch_2, lr: 0.00100, 350/519: Train average loss: 0.401
04/11/2022 11:22:35 AM - INFO - global step: 879, epoch_2, lr: 0.00100, 360/519: Train average loss: 0.401
04/11/2022 11:22:39 AM - INFO - global step: 889, epoch_2, lr: 0.00100, 370/519: Train average loss: 0.400
04/11/2022 11:22:44 AM - INFO - global step: 899, epoch_2, lr: 0.00100, 380/519: Train average loss: 0.399
04/11/2022 11:22:48 AM - INFO - global step: 909, epoch_2, lr: 0.00100, 390/519: Train average loss: 0.398
04/11/2022 11:22:52 AM - INFO - global step: 919, epoch_2, lr: 0.00100, 400/519: Train average loss: 0.398
04/11/2022 11:22:57 AM - INFO - global step: 929, epoch_2, lr: 0.00100, 410/519: Train average loss: 0.397
04/11/2022 11:23:01 AM - INFO - global step: 939, epoch_2, lr: 0.00100, 420/519: Train average loss: 0.396
04/11/2022 11:23:05 AM - INFO - global step: 949, epoch_2, lr: 0.00100, 430/519: Train average loss: 0.396
04/11/2022 11:23:10 AM - INFO - global step: 959, epoch_2, lr: 0.00100, 440/519: Train average loss: 0.396
04/11/2022 11:23:14 AM - INFO - global step: 969, epoch_2, lr: 0.00100, 450/519: Train average loss: 0.397
04/11/2022 11:23:18 AM - INFO - global step: 979, epoch_2, lr: 0.00100, 460/519: Train average loss: 0.397
04/11/2022 11:23:23 AM - INFO - global step: 989, epoch_2, lr: 0.00100, 470/519: Train average loss: 0.397
04/11/2022 11:23:27 AM - INFO - global step: 999, epoch_2, lr: 0.00100, 480/519: Train average loss: 0.396
04/11/2022 11:23:32 AM - INFO - global step: 1009, epoch_2, lr: 0.00100, 490/519: Train average loss: 0.396
04/11/2022 11:23:36 AM - INFO - global step: 1019, epoch_2, lr: 0.00100, 500/519: Train average loss: 0.395
04/11/2022 11:23:40 AM - INFO - global step: 1029, epoch_2, lr: 0.00100, 510/519: Train average loss: 0.396
04/11/2022 11:23:44 AM - INFO - ==========================================================
04/11/2022 11:23:44 AM - INFO - epoch_2: Train set(Aug) miou is: 0.488
04/11/2022 11:23:52 AM - INFO - epoch_2: Valid set average loss is: 0.339
04/11/2022 11:23:52 AM - INFO - epoch_2: Valid set miou is: 0.513
04/11/2022 11:23:52 AM - INFO - ==========================================================
04/11/2022 11:23:56 AM - INFO - global step: 1048, epoch_3, lr: 0.00100, 10/519: Train average loss: 0.373
04/11/2022 11:24:01 AM - INFO - global step: 1058, epoch_3, lr: 0.00100, 20/519: Train average loss: 0.354
04/11/2022 11:24:05 AM - INFO - global step: 1068, epoch_3, lr: 0.00100, 30/519: Train average loss: 0.374
04/11/2022 11:24:10 AM - INFO - global step: 1078, epoch_3, lr: 0.00100, 40/519: Train average loss: 0.375
04/11/2022 11:24:14 AM - INFO - global step: 1088, epoch_3, lr: 0.00100, 50/519: Train average loss: 0.378
04/11/2022 11:24:19 AM - INFO - global step: 1098, epoch_3, lr: 0.00100, 60/519: Train average loss: 0.374
04/11/2022 11:24:23 AM - INFO - global step: 1108, epoch_3, lr: 0.00100, 70/519: Train average loss: 0.383
04/11/2022 11:24:27 AM - INFO - global step: 1118, epoch_3, lr: 0.00100, 80/519: Train average loss: 0.381
04/11/2022 11:24:32 AM - INFO - global step: 1128, epoch_3, lr: 0.00100, 90/519: Train average loss: 0.377
04/11/2022 11:24:36 AM - INFO - global step: 1138, epoch_3, lr: 0.00100, 100/519: Train average loss: 0.376
04/11/2022 11:24:41 AM - INFO - global step: 1148, epoch_3, lr: 0.00100, 110/519: Train average loss: 0.375
04/11/2022 11:24:45 AM - INFO - global step: 1158, epoch_3, lr: 0.00100, 120/519: Train average loss: 0.379
04/11/2022 11:24:49 AM - INFO - global step: 1168, epoch_3, lr: 0.00100, 130/519: Train average loss: 0.381
04/11/2022 11:24:54 AM - INFO - global step: 1178, epoch_3, lr: 0.00100, 140/519: Train average loss: 0.383
04/11/2022 11:24:58 AM - INFO - global step: 1188, epoch_3, lr: 0.00100, 150/519: Train average loss: 0.383
04/11/2022 11:25:02 AM - INFO - global step: 1198, epoch_3, lr: 0.00100, 160/519: Train average loss: 0.384
04/11/2022 11:25:07 AM - INFO - global step: 1208, epoch_3, lr: 0.00100, 170/519: Train average loss: 0.383
04/11/2022 11:25:11 AM - INFO - global step: 1218, epoch_3, lr: 0.00100, 180/519: Train average loss: 0.382
04/11/2022 11:25:15 AM - INFO - global step: 1228, epoch_3, lr: 0.00100, 190/519: Train average loss: 0.382
04/11/2022 11:25:20 AM - INFO - global step: 1238, epoch_3, lr: 0.00100, 200/519: Train average loss: 0.382
04/11/2022 11:25:24 AM - INFO - global step: 1248, epoch_3, lr: 0.00100, 210/519: Train average loss: 0.383
04/11/2022 11:25:29 AM - INFO - global step: 1258, epoch_3, lr: 0.00100, 220/519: Train average loss: 0.381
04/11/2022 11:25:33 AM - INFO - global step: 1268, epoch_3, lr: 0.00100, 230/519: Train average loss: 0.380
04/11/2022 11:25:37 AM - INFO - global step: 1278, epoch_3, lr: 0.00100, 240/519: Train average loss: 0.382
04/11/2022 11:25:42 AM - INFO - global step: 1288, epoch_3, lr: 0.00100, 250/519: Train average loss: 0.381
04/11/2022 11:25:46 AM - INFO - global step: 1298, epoch_3, lr: 0.00100, 260/519: Train average loss: 0.380
04/11/2022 11:25:50 AM - INFO - global step: 1308, epoch_3, lr: 0.00100, 270/519: Train average loss: 0.379
04/11/2022 11:25:55 AM - INFO - global step: 1318, epoch_3, lr: 0.00100, 280/519: Train average loss: 0.379
04/11/2022 11:25:59 AM - INFO - global step: 1328, epoch_3, lr: 0.00100, 290/519: Train average loss: 0.380
04/11/2022 11:26:04 AM - INFO - global step: 1338, epoch_3, lr: 0.00100, 300/519: Train average loss: 0.380
04/11/2022 11:26:08 AM - INFO - global step: 1348, epoch_3, lr: 0.00100, 310/519: Train average loss: 0.380
04/11/2022 11:26:12 AM - INFO - global step: 1358, epoch_3, lr: 0.00100, 320/519: Train average loss: 0.379
04/11/2022 11:26:17 AM - INFO - global step: 1368, epoch_3, lr: 0.00100, 330/519: Train average loss: 0.378
04/11/2022 11:26:21 AM - INFO - global step: 1378, epoch_3, lr: 0.00100, 340/519: Train average loss: 0.378
04/11/2022 11:26:26 AM - INFO - global step: 1388, epoch_3, lr: 0.00100, 350/519: Train average loss: 0.378
04/11/2022 11:26:30 AM - INFO - global step: 1398, epoch_3, lr: 0.00100, 360/519: Train average loss: 0.377
04/11/2022 11:26:34 AM - INFO - global step: 1408, epoch_3, lr: 0.00100, 370/519: Train average loss: 0.377
04/11/2022 11:26:39 AM - INFO - global step: 1418, epoch_3, lr: 0.00100, 380/519: Train average loss: 0.377
04/11/2022 11:26:43 AM - INFO - global step: 1428, epoch_3, lr: 0.00100, 390/519: Train average loss: 0.377
04/11/2022 11:26:48 AM - INFO - global step: 1438, epoch_3, lr: 0.00100, 400/519: Train average loss: 0.376
04/11/2022 11:26:52 AM - INFO - global step: 1448, epoch_3, lr: 0.00100, 410/519: Train average loss: 0.377
04/11/2022 11:26:56 AM - INFO - global step: 1458, epoch_3, lr: 0.00100, 420/519: Train average loss: 0.377
04/11/2022 11:27:01 AM - INFO - global step: 1468, epoch_3, lr: 0.00100, 430/519: Train average loss: 0.376
04/11/2022 11:27:05 AM - INFO - global step: 1478, epoch_3, lr: 0.00100, 440/519: Train average loss: 0.376
04/11/2022 11:27:09 AM - INFO - global step: 1488, epoch_3, lr: 0.00100, 450/519: Train average loss: 0.375
04/11/2022 11:27:14 AM - INFO - global step: 1498, epoch_3, lr: 0.00100, 460/519: Train average loss: 0.374
04/11/2022 11:27:18 AM - INFO - global step: 1508, epoch_3, lr: 0.00100, 470/519: Train average loss: 0.373
04/11/2022 11:27:22 AM - INFO - global step: 1518, epoch_3, lr: 0.00100, 480/519: Train average loss: 0.374
04/11/2022 11:27:27 AM - INFO - global step: 1528, epoch_3, lr: 0.00100, 490/519: Train average loss: 0.375
04/11/2022 11:27:31 AM - INFO - global step: 1538, epoch_3, lr: 0.00100, 500/519: Train average loss: 0.375
04/11/2022 11:27:36 AM - INFO - global step: 1548, epoch_3, lr: 0.00100, 510/519: Train average loss: 0.375
04/11/2022 11:27:39 AM - INFO - ==========================================================
04/11/2022 11:27:39 AM - INFO - epoch_3: Train set(Aug) miou is: 0.506
04/11/2022 11:27:47 AM - INFO - epoch_3: Valid set average loss is: 0.299
04/11/2022 11:27:47 AM - INFO - epoch_3: Valid set miou is: 0.581
04/11/2022 11:27:47 AM - INFO - ==========================================================
04/11/2022 11:27:52 AM - INFO - global step: 1567, epoch_4, lr: 0.00100, 10/519: Train average loss: 0.374
04/11/2022 11:27:56 AM - INFO - global step: 1577, epoch_4, lr: 0.00100, 20/519: Train average loss: 0.353
04/11/2022 11:28:00 AM - INFO - global step: 1587, epoch_4, lr: 0.00100, 30/519: Train average loss: 0.353
04/11/2022 11:28:05 AM - INFO - global step: 1597, epoch_4, lr: 0.00100, 40/519: Train average loss: 0.343
04/11/2022 11:28:09 AM - INFO - global step: 1607, epoch_4, lr: 0.00100, 50/519: Train average loss: 0.354
04/11/2022 11:28:13 AM - INFO - global step: 1617, epoch_4, lr: 0.00100, 60/519: Train average loss: 0.359
04/11/2022 11:28:18 AM - INFO - global step: 1627, epoch_4, lr: 0.00100, 70/519: Train average loss: 0.358
04/11/2022 11:28:22 AM - INFO - global step: 1637, epoch_4, lr: 0.00100, 80/519: Train average loss: 0.360
04/11/2022 11:28:26 AM - INFO - global step: 1647, epoch_4, lr: 0.00100, 90/519: Train average loss: 0.362
04/11/2022 11:28:31 AM - INFO - global step: 1657, epoch_4, lr: 0.00100, 100/519: Train average loss: 0.365
04/11/2022 11:28:35 AM - INFO - global step: 1667, epoch_4, lr: 0.00100, 110/519: Train average loss: 0.372
04/11/2022 11:28:40 AM - INFO - global step: 1677, epoch_4, lr: 0.00100, 120/519: Train average loss: 0.371
04/11/2022 11:28:44 AM - INFO - global step: 1687, epoch_4, lr: 0.00100, 130/519: Train average loss: 0.372
04/11/2022 11:28:48 AM - INFO - global step: 1697, epoch_4, lr: 0.00100, 140/519: Train average loss: 0.370
04/11/2022 11:28:52 AM - INFO - global step: 1707, epoch_4, lr: 0.00100, 150/519: Train average loss: 0.371
04/11/2022 11:28:57 AM - INFO - global step: 1717, epoch_4, lr: 0.00100, 160/519: Train average loss: 0.371
04/11/2022 11:29:01 AM - INFO - global step: 1727, epoch_4, lr: 0.00100, 170/519: Train average loss: 0.371
04/11/2022 11:29:05 AM - INFO - global step: 1737, epoch_4, lr: 0.00100, 180/519: Train average loss: 0.373
04/11/2022 11:29:09 AM - INFO - global step: 1747, epoch_4, lr: 0.00100, 190/519: Train average loss: 0.372
04/11/2022 11:29:14 AM - INFO - global step: 1757, epoch_4, lr: 0.00100, 200/519: Train average loss: 0.371
04/11/2022 11:29:18 AM - INFO - global step: 1767, epoch_4, lr: 0.00100, 210/519: Train average loss: 0.373
04/11/2022 11:29:22 AM - INFO - global step: 1777, epoch_4, lr: 0.00100, 220/519: Train average loss: 0.373
04/11/2022 11:29:26 AM - INFO - global step: 1787, epoch_4, lr: 0.00100, 230/519: Train average loss: 0.373
04/11/2022 11:29:30 AM - INFO - global step: 1797, epoch_4, lr: 0.00100, 240/519: Train average loss: 0.371
04/11/2022 11:29:35 AM - INFO - global step: 1807, epoch_4, lr: 0.00100, 250/519: Train average loss: 0.370
04/11/2022 11:29:39 AM - INFO - global step: 1817, epoch_4, lr: 0.00100, 260/519: Train average loss: 0.369
04/11/2022 11:29:43 AM - INFO - global step: 1827, epoch_4, lr: 0.00100, 270/519: Train average loss: 0.372
04/11/2022 11:29:47 AM - INFO - global step: 1837, epoch_4, lr: 0.00100, 280/519: Train average loss: 0.372
04/11/2022 11:29:52 AM - INFO - global step: 1847, epoch_4, lr: 0.00100, 290/519: Train average loss: 0.371
04/11/2022 11:29:56 AM - INFO - global step: 1857, epoch_4, lr: 0.00100, 300/519: Train average loss: 0.372
04/11/2022 11:30:00 AM - INFO - global step: 1867, epoch_4, lr: 0.00100, 310/519: Train average loss: 0.372
04/11/2022 11:30:04 AM - INFO - global step: 1877, epoch_4, lr: 0.00100, 320/519: Train average loss: 0.371
04/11/2022 11:30:08 AM - INFO - global step: 1887, epoch_4, lr: 0.00100, 330/519: Train average loss: 0.371
04/11/2022 11:30:13 AM - INFO - global step: 1897, epoch_4, lr: 0.00100, 340/519: Train average loss: 0.370
04/11/2022 11:30:17 AM - INFO - global step: 1907, epoch_4, lr: 0.00100, 350/519: Train average loss: 0.370
04/11/2022 11:30:21 AM - INFO - global step: 1917, epoch_4, lr: 0.00100, 360/519: Train average loss: 0.369
04/11/2022 11:30:26 AM - INFO - global step: 1927, epoch_4, lr: 0.00100, 370/519: Train average loss: 0.368
04/11/2022 11:30:30 AM - INFO - global step: 1937, epoch_4, lr: 0.00100, 380/519: Train average loss: 0.368
04/11/2022 11:30:34 AM - INFO - global step: 1947, epoch_4, lr: 0.00100, 390/519: Train average loss: 0.366
04/11/2022 11:30:38 AM - INFO - global step: 1957, epoch_4, lr: 0.00100, 400/519: Train average loss: 0.365
04/11/2022 11:30:42 AM - INFO - global step: 1967, epoch_4, lr: 0.00100, 410/519: Train average loss: 0.365
04/11/2022 11:30:47 AM - INFO - global step: 1977, epoch_4, lr: 0.00100, 420/519: Train average loss: 0.365
04/11/2022 11:30:51 AM - INFO - global step: 1987, epoch_4, lr: 0.00100, 430/519: Train average loss: 0.364
04/11/2022 11:30:55 AM - INFO - global step: 1997, epoch_4, lr: 0.00100, 440/519: Train average loss: 0.364
04/11/2022 11:30:59 AM - INFO - global step: 2007, epoch_4, lr: 0.00090, 450/519: Train average loss: 0.363
04/11/2022 11:31:03 AM - INFO - global step: 2017, epoch_4, lr: 0.00090, 460/519: Train average loss: 0.363
04/11/2022 11:31:07 AM - INFO - global step: 2027, epoch_4, lr: 0.00090, 470/519: Train average loss: 0.362
04/11/2022 11:31:12 AM - INFO - global step: 2037, epoch_4, lr: 0.00090, 480/519: Train average loss: 0.364
04/11/2022 11:31:16 AM - INFO - global step: 2047, epoch_4, lr: 0.00090, 490/519: Train average loss: 0.363
04/11/2022 11:31:20 AM - INFO - global step: 2057, epoch_4, lr: 0.00090, 500/519: Train average loss: 0.364
04/11/2022 11:31:24 AM - INFO - global step: 2067, epoch_4, lr: 0.00090, 510/519: Train average loss: 0.364
04/11/2022 11:31:28 AM - INFO - ==========================================================
04/11/2022 11:31:28 AM - INFO - epoch_4: Train set(Aug) miou is: 0.516
04/11/2022 11:31:36 AM - INFO - epoch_4: Valid set average loss is: 0.316
04/11/2022 11:31:36 AM - INFO - epoch_4: Valid set miou is: 0.532
04/11/2022 11:31:36 AM - INFO - ==========================================================
04/11/2022 11:31:40 AM - INFO - global step: 2086, epoch_5, lr: 0.00090, 10/519: Train average loss: 0.319
04/11/2022 11:31:44 AM - INFO - global step: 2096, epoch_5, lr: 0.00090, 20/519: Train average loss: 0.348
04/11/2022 11:31:48 AM - INFO - global step: 2106, epoch_5, lr: 0.00090, 30/519: Train average loss: 0.364
04/11/2022 11:31:52 AM - INFO - global step: 2116, epoch_5, lr: 0.00090, 40/519: Train average loss: 0.352
04/11/2022 11:31:56 AM - INFO - global step: 2126, epoch_5, lr: 0.00090, 50/519: Train average loss: 0.347
04/11/2022 11:32:01 AM - INFO - global step: 2136, epoch_5, lr: 0.00090, 60/519: Train average loss: 0.348
04/11/2022 11:32:05 AM - INFO - global step: 2146, epoch_5, lr: 0.00090, 70/519: Train average loss: 0.345
04/11/2022 11:32:09 AM - INFO - global step: 2156, epoch_5, lr: 0.00090, 80/519: Train average loss: 0.346
04/11/2022 11:32:13 AM - INFO - global step: 2166, epoch_5, lr: 0.00090, 90/519: Train average loss: 0.349
04/11/2022 11:32:18 AM - INFO - global step: 2176, epoch_5, lr: 0.00090, 100/519: Train average loss: 0.349
04/11/2022 11:32:22 AM - INFO - global step: 2186, epoch_5, lr: 0.00090, 110/519: Train average loss: 0.351
04/11/2022 11:32:26 AM - INFO - global step: 2196, epoch_5, lr: 0.00090, 120/519: Train average loss: 0.351
04/11/2022 11:32:30 AM - INFO - global step: 2206, epoch_5, lr: 0.00090, 130/519: Train average loss: 0.355
04/11/2022 11:32:34 AM - INFO - global step: 2216, epoch_5, lr: 0.00090, 140/519: Train average loss: 0.355
04/11/2022 11:32:39 AM - INFO - global step: 2226, epoch_5, lr: 0.00090, 150/519: Train average loss: 0.356
04/11/2022 11:32:43 AM - INFO - global step: 2236, epoch_5, lr: 0.00090, 160/519: Train average loss: 0.355
04/11/2022 11:32:47 AM - INFO - global step: 2246, epoch_5, lr: 0.00090, 170/519: Train average loss: 0.356
04/11/2022 11:32:51 AM - INFO - global step: 2256, epoch_5, lr: 0.00090, 180/519: Train average loss: 0.358
04/11/2022 11:32:55 AM - INFO - global step: 2266, epoch_5, lr: 0.00090, 190/519: Train average loss: 0.361
04/11/2022 11:33:00 AM - INFO - global step: 2276, epoch_5, lr: 0.00090, 200/519: Train average loss: 0.360
04/11/2022 11:33:04 AM - INFO - global step: 2286, epoch_5, lr: 0.00090, 210/519: Train average loss: 0.359
04/11/2022 11:33:08 AM - INFO - global step: 2296, epoch_5, lr: 0.00090, 220/519: Train average loss: 0.359
04/11/2022 11:33:12 AM - INFO - global step: 2306, epoch_5, lr: 0.00090, 230/519: Train average loss: 0.357
04/11/2022 11:33:17 AM - INFO - global step: 2316, epoch_5, lr: 0.00090, 240/519: Train average loss: 0.358
04/11/2022 11:33:21 AM - INFO - global step: 2326, epoch_5, lr: 0.00090, 250/519: Train average loss: 0.357
04/11/2022 11:33:25 AM - INFO - global step: 2336, epoch_5, lr: 0.00090, 260/519: Train average loss: 0.356
04/11/2022 11:33:29 AM - INFO - global step: 2346, epoch_5, lr: 0.00090, 270/519: Train average loss: 0.355
04/11/2022 11:33:33 AM - INFO - global step: 2356, epoch_5, lr: 0.00090, 280/519: Train average loss: 0.355
04/11/2022 11:33:38 AM - INFO - global step: 2366, epoch_5, lr: 0.00090, 290/519: Train average loss: 0.355
04/11/2022 11:33:42 AM - INFO - global step: 2376, epoch_5, lr: 0.00090, 300/519: Train average loss: 0.356
04/11/2022 11:33:46 AM - INFO - global step: 2386, epoch_5, lr: 0.00090, 310/519: Train average loss: 0.356
04/11/2022 11:33:50 AM - INFO - global step: 2396, epoch_5, lr: 0.00090, 320/519: Train average loss: 0.356
04/11/2022 11:33:54 AM - INFO - global step: 2406, epoch_5, lr: 0.00090, 330/519: Train average loss: 0.356
04/11/2022 11:33:58 AM - INFO - global step: 2416, epoch_5, lr: 0.00090, 340/519: Train average loss: 0.356
04/11/2022 11:34:03 AM - INFO - global step: 2426, epoch_5, lr: 0.00090, 350/519: Train average loss: 0.356
04/11/2022 11:34:07 AM - INFO - global step: 2436, epoch_5, lr: 0.00090, 360/519: Train average loss: 0.355
04/11/2022 11:34:11 AM - INFO - global step: 2446, epoch_5, lr: 0.00090, 370/519: Train average loss: 0.355
04/11/2022 11:34:15 AM - INFO - global step: 2456, epoch_5, lr: 0.00090, 380/519: Train average loss: 0.354
04/11/2022 11:34:20 AM - INFO - global step: 2466, epoch_5, lr: 0.00090, 390/519: Train average loss: 0.354
04/11/2022 11:34:24 AM - INFO - global step: 2476, epoch_5, lr: 0.00090, 400/519: Train average loss: 0.353
04/11/2022 11:34:28 AM - INFO - global step: 2486, epoch_5, lr: 0.00090, 410/519: Train average loss: 0.353
04/11/2022 11:34:32 AM - INFO - global step: 2496, epoch_5, lr: 0.00090, 420/519: Train average loss: 0.353
04/11/2022 11:34:37 AM - INFO - global step: 2506, epoch_5, lr: 0.00090, 430/519: Train average loss: 0.353
04/11/2022 11:34:41 AM - INFO - global step: 2516, epoch_5, lr: 0.00090, 440/519: Train average loss: 0.354
04/11/2022 11:34:45 AM - INFO - global step: 2526, epoch_5, lr: 0.00090, 450/519: Train average loss: 0.354
04/11/2022 11:34:50 AM - INFO - global step: 2536, epoch_5, lr: 0.00090, 460/519: Train average loss: 0.354
04/11/2022 11:34:54 AM - INFO - global step: 2546, epoch_5, lr: 0.00090, 470/519: Train average loss: 0.354
04/11/2022 11:34:58 AM - INFO - global step: 2556, epoch_5, lr: 0.00090, 480/519: Train average loss: 0.354
04/11/2022 11:35:02 AM - INFO - global step: 2566, epoch_5, lr: 0.00090, 490/519: Train average loss: 0.354
04/11/2022 11:35:06 AM - INFO - global step: 2576, epoch_5, lr: 0.00090, 500/519: Train average loss: 0.354
04/11/2022 11:35:11 AM - INFO - global step: 2586, epoch_5, lr: 0.00090, 510/519: Train average loss: 0.353
04/11/2022 11:35:14 AM - INFO - ==========================================================
04/11/2022 11:35:14 AM - INFO - epoch_5: Train set(Aug) miou is: 0.525
04/11/2022 11:35:22 AM - INFO - epoch_5: Valid set average loss is: 0.321
04/11/2022 11:35:22 AM - INFO - epoch_5: Valid set miou is: 0.523
04/11/2022 11:35:22 AM - INFO - ==========================================================
04/11/2022 11:35:27 AM - INFO - global step: 2605, epoch_6, lr: 0.00090, 10/519: Train average loss: 0.383
04/11/2022 11:35:31 AM - INFO - global step: 2615, epoch_6, lr: 0.00090, 20/519: Train average loss: 0.359
04/11/2022 11:35:35 AM - INFO - global step: 2625, epoch_6, lr: 0.00090, 30/519: Train average loss: 0.349
04/11/2022 11:35:39 AM - INFO - global step: 2635, epoch_6, lr: 0.00090, 40/519: Train average loss: 0.350
04/11/2022 11:35:44 AM - INFO - global step: 2645, epoch_6, lr: 0.00090, 50/519: Train average loss: 0.346
04/11/2022 11:35:48 AM - INFO - global step: 2655, epoch_6, lr: 0.00090, 60/519: Train average loss: 0.348
04/11/2022 11:35:52 AM - INFO - global step: 2665, epoch_6, lr: 0.00090, 70/519: Train average loss: 0.349
04/11/2022 11:35:56 AM - INFO - global step: 2675, epoch_6, lr: 0.00090, 80/519: Train average loss: 0.351
04/11/2022 11:36:01 AM - INFO - global step: 2685, epoch_6, lr: 0.00090, 90/519: Train average loss: 0.351
04/11/2022 11:36:05 AM - INFO - global step: 2695, epoch_6, lr: 0.00090, 100/519: Train average loss: 0.353
04/11/2022 11:36:09 AM - INFO - global step: 2705, epoch_6, lr: 0.00090, 110/519: Train average loss: 0.352
04/11/2022 11:36:13 AM - INFO - global step: 2715, epoch_6, lr: 0.00090, 120/519: Train average loss: 0.352
04/11/2022 11:36:17 AM - INFO - global step: 2725, epoch_6, lr: 0.00090, 130/519: Train average loss: 0.349
04/11/2022 11:36:22 AM - INFO - global step: 2735, epoch_6, lr: 0.00090, 140/519: Train average loss: 0.349
04/11/2022 11:36:26 AM - INFO - global step: 2745, epoch_6, lr: 0.00090, 150/519: Train average loss: 0.348
04/11/2022 11:36:30 AM - INFO - global step: 2755, epoch_6, lr: 0.00090, 160/519: Train average loss: 0.349
04/11/2022 11:36:35 AM - INFO - global step: 2765, epoch_6, lr: 0.00090, 170/519: Train average loss: 0.349
04/11/2022 11:36:39 AM - INFO - global step: 2775, epoch_6, lr: 0.00090, 180/519: Train average loss: 0.349
04/11/2022 11:36:43 AM - INFO - global step: 2785, epoch_6, lr: 0.00090, 190/519: Train average loss: 0.347
04/11/2022 11:36:47 AM - INFO - global step: 2795, epoch_6, lr: 0.00090, 200/519: Train average loss: 0.347
04/11/2022 11:36:51 AM - INFO - global step: 2805, epoch_6, lr: 0.00090, 210/519: Train average loss: 0.345
04/11/2022 11:36:55 AM - INFO - global step: 2815, epoch_6, lr: 0.00090, 220/519: Train average loss: 0.347
04/11/2022 11:37:00 AM - INFO - global step: 2825, epoch_6, lr: 0.00090, 230/519: Train average loss: 0.346
04/11/2022 11:37:04 AM - INFO - global step: 2835, epoch_6, lr: 0.00090, 240/519: Train average loss: 0.348
04/11/2022 11:37:08 AM - INFO - global step: 2845, epoch_6, lr: 0.00090, 250/519: Train average loss: 0.348
04/11/2022 11:37:12 AM - INFO - global step: 2855, epoch_6, lr: 0.00090, 260/519: Train average loss: 0.348
04/11/2022 11:37:16 AM - INFO - global step: 2865, epoch_6, lr: 0.00090, 270/519: Train average loss: 0.347
04/11/2022 11:37:20 AM - INFO - global step: 2875, epoch_6, lr: 0.00090, 280/519: Train average loss: 0.347
04/11/2022 11:37:24 AM - INFO - global step: 2885, epoch_6, lr: 0.00090, 290/519: Train average loss: 0.348
04/11/2022 11:37:29 AM - INFO - global step: 2895, epoch_6, lr: 0.00090, 300/519: Train average loss: 0.347
04/11/2022 11:37:33 AM - INFO - global step: 2905, epoch_6, lr: 0.00090, 310/519: Train average loss: 0.347
04/11/2022 11:37:37 AM - INFO - global step: 2915, epoch_6, lr: 0.00090, 320/519: Train average loss: 0.346
04/11/2022 11:37:41 AM - INFO - global step: 2925, epoch_6, lr: 0.00090, 330/519: Train average loss: 0.346
04/11/2022 11:37:45 AM - INFO - global step: 2935, epoch_6, lr: 0.00090, 340/519: Train average loss: 0.346
04/11/2022 11:37:50 AM - INFO - global step: 2945, epoch_6, lr: 0.00090, 350/519: Train average loss: 0.346
04/11/2022 11:37:54 AM - INFO - global step: 2955, epoch_6, lr: 0.00090, 360/519: Train average loss: 0.346
04/11/2022 11:37:58 AM - INFO - global step: 2965, epoch_6, lr: 0.00090, 370/519: Train average loss: 0.346
04/11/2022 11:38:02 AM - INFO - global step: 2975, epoch_6, lr: 0.00090, 380/519: Train average loss: 0.345
04/11/2022 11:38:06 AM - INFO - global step: 2985, epoch_6, lr: 0.00090, 390/519: Train average loss: 0.344
04/11/2022 11:38:10 AM - INFO - global step: 2995, epoch_6, lr: 0.00090, 400/519: Train average loss: 0.344
04/11/2022 11:38:15 AM - INFO - global step: 3005, epoch_6, lr: 0.00090, 410/519: Train average loss: 0.343
04/11/2022 11:38:19 AM - INFO - global step: 3015, epoch_6, lr: 0.00090, 420/519: Train average loss: 0.343
04/11/2022 11:38:23 AM - INFO - global step: 3025, epoch_6, lr: 0.00090, 430/519: Train average loss: 0.343
04/11/2022 11:38:27 AM - INFO - global step: 3035, epoch_6, lr: 0.00090, 440/519: Train average loss: 0.343
04/11/2022 11:38:31 AM - INFO - global step: 3045, epoch_6, lr: 0.00090, 450/519: Train average loss: 0.342
04/11/2022 11:38:36 AM - INFO - global step: 3055, epoch_6, lr: 0.00090, 460/519: Train average loss: 0.341
04/11/2022 11:38:40 AM - INFO - global step: 3065, epoch_6, lr: 0.00090, 470/519: Train average loss: 0.343
04/11/2022 11:38:44 AM - INFO - global step: 3075, epoch_6, lr: 0.00090, 480/519: Train average loss: 0.342
04/11/2022 11:38:48 AM - INFO - global step: 3085, epoch_6, lr: 0.00090, 490/519: Train average loss: 0.343
04/11/2022 11:38:52 AM - INFO - global step: 3095, epoch_6, lr: 0.00090, 500/519: Train average loss: 0.343
04/11/2022 11:38:57 AM - INFO - global step: 3105, epoch_6, lr: 0.00090, 510/519: Train average loss: 0.342
04/11/2022 11:39:00 AM - INFO - ==========================================================
04/11/2022 11:39:00 AM - INFO - epoch_6: Train set(Aug) miou is: 0.541
04/11/2022 11:39:08 AM - INFO - epoch_6: Valid set average loss is: 0.300
04/11/2022 11:39:08 AM - INFO - epoch_6: Valid set miou is: 0.543
04/11/2022 11:39:08 AM - INFO - ==========================================================
04/11/2022 11:39:12 AM - INFO - global step: 3124, epoch_7, lr: 0.00090, 10/519: Train average loss: 0.320
04/11/2022 11:39:16 AM - INFO - global step: 3134, epoch_7, lr: 0.00090, 20/519: Train average loss: 0.331
04/11/2022 11:39:21 AM - INFO - global step: 3144, epoch_7, lr: 0.00090, 30/519: Train average loss: 0.330
04/11/2022 11:39:25 AM - INFO - global step: 3154, epoch_7, lr: 0.00090, 40/519: Train average loss: 0.331
04/11/2022 11:39:29 AM - INFO - global step: 3164, epoch_7, lr: 0.00090, 50/519: Train average loss: 0.330
04/11/2022 11:39:33 AM - INFO - global step: 3174, epoch_7, lr: 0.00090, 60/519: Train average loss: 0.329
04/11/2022 11:39:38 AM - INFO - global step: 3184, epoch_7, lr: 0.00090, 70/519: Train average loss: 0.329
04/11/2022 11:39:42 AM - INFO - global step: 3194, epoch_7, lr: 0.00090, 80/519: Train average loss: 0.328
04/11/2022 11:39:46 AM - INFO - global step: 3204, epoch_7, lr: 0.00090, 90/519: Train average loss: 0.323
04/11/2022 11:39:51 AM - INFO - global step: 3214, epoch_7, lr: 0.00090, 100/519: Train average loss: 0.322
04/11/2022 11:39:55 AM - INFO - global step: 3224, epoch_7, lr: 0.00090, 110/519: Train average loss: 0.325
04/11/2022 11:39:59 AM - INFO - global step: 3234, epoch_7, lr: 0.00090, 120/519: Train average loss: 0.328
04/11/2022 11:40:03 AM - INFO - global step: 3244, epoch_7, lr: 0.00090, 130/519: Train average loss: 0.330
04/11/2022 11:40:08 AM - INFO - global step: 3254, epoch_7, lr: 0.00090, 140/519: Train average loss: 0.334
04/11/2022 11:40:12 AM - INFO - global step: 3264, epoch_7, lr: 0.00090, 150/519: Train average loss: 0.337
04/11/2022 11:40:16 AM - INFO - global step: 3274, epoch_7, lr: 0.00090, 160/519: Train average loss: 0.336
04/11/2022 11:40:20 AM - INFO - global step: 3284, epoch_7, lr: 0.00090, 170/519: Train average loss: 0.340
04/11/2022 11:40:24 AM - INFO - global step: 3294, epoch_7, lr: 0.00090, 180/519: Train average loss: 0.339
04/11/2022 11:40:29 AM - INFO - global step: 3304, epoch_7, lr: 0.00090, 190/519: Train average loss: 0.338
04/11/2022 11:40:33 AM - INFO - global step: 3314, epoch_7, lr: 0.00090, 200/519: Train average loss: 0.337
04/11/2022 11:40:37 AM - INFO - global step: 3324, epoch_7, lr: 0.00090, 210/519: Train average loss: 0.337
04/11/2022 11:40:41 AM - INFO - global step: 3334, epoch_7, lr: 0.00090, 220/519: Train average loss: 0.336
04/11/2022 11:40:45 AM - INFO - global step: 3344, epoch_7, lr: 0.00090, 230/519: Train average loss: 0.335
04/11/2022 11:40:50 AM - INFO - global step: 3354, epoch_7, lr: 0.00090, 240/519: Train average loss: 0.335
04/11/2022 11:40:54 AM - INFO - global step: 3364, epoch_7, lr: 0.00090, 250/519: Train average loss: 0.335
04/11/2022 11:40:58 AM - INFO - global step: 3374, epoch_7, lr: 0.00090, 260/519: Train average loss: 0.336
04/11/2022 11:41:02 AM - INFO - global step: 3384, epoch_7, lr: 0.00090, 270/519: Train average loss: 0.336
04/11/2022 11:41:07 AM - INFO - global step: 3394, epoch_7, lr: 0.00090, 280/519: Train average loss: 0.335
04/11/2022 11:41:11 AM - INFO - global step: 3404, epoch_7, lr: 0.00090, 290/519: Train average loss: 0.334
04/11/2022 11:41:15 AM - INFO - global step: 3414, epoch_7, lr: 0.00090, 300/519: Train average loss: 0.334
04/11/2022 11:41:19 AM - INFO - global step: 3424, epoch_7, lr: 0.00090, 310/519: Train average loss: 0.334
04/11/2022 11:41:23 AM - INFO - global step: 3434, epoch_7, lr: 0.00090, 320/519: Train average loss: 0.335
04/11/2022 11:41:28 AM - INFO - global step: 3444, epoch_7, lr: 0.00090, 330/519: Train average loss: 0.334
04/11/2022 11:41:32 AM - INFO - global step: 3454, epoch_7, lr: 0.00090, 340/519: Train average loss: 0.334
04/11/2022 11:41:36 AM - INFO - global step: 3464, epoch_7, lr: 0.00090, 350/519: Train average loss: 0.333
04/11/2022 11:41:40 AM - INFO - global step: 3474, epoch_7, lr: 0.00090, 360/519: Train average loss: 0.333
04/11/2022 11:41:44 AM - INFO - global step: 3484, epoch_7, lr: 0.00090, 370/519: Train average loss: 0.333
04/11/2022 11:41:49 AM - INFO - global step: 3494, epoch_7, lr: 0.00090, 380/519: Train average loss: 0.333
04/11/2022 11:41:53 AM - INFO - global step: 3504, epoch_7, lr: 0.00090, 390/519: Train average loss: 0.333
04/11/2022 11:41:57 AM - INFO - global step: 3514, epoch_7, lr: 0.00090, 400/519: Train average loss: 0.333
04/11/2022 11:42:01 AM - INFO - global step: 3524, epoch_7, lr: 0.00090, 410/519: Train average loss: 0.333
04/11/2022 11:42:06 AM - INFO - global step: 3534, epoch_7, lr: 0.00090, 420/519: Train average loss: 0.332
04/11/2022 11:42:10 AM - INFO - global step: 3544, epoch_7, lr: 0.00090, 430/519: Train average loss: 0.332
04/11/2022 11:42:14 AM - INFO - global step: 3554, epoch_7, lr: 0.00090, 440/519: Train average loss: 0.332
04/11/2022 11:42:18 AM - INFO - global step: 3564, epoch_7, lr: 0.00090, 450/519: Train average loss: 0.333
04/11/2022 11:42:22 AM - INFO - global step: 3574, epoch_7, lr: 0.00090, 460/519: Train average loss: 0.333
04/11/2022 11:42:26 AM - INFO - global step: 3584, epoch_7, lr: 0.00090, 470/519: Train average loss: 0.334
04/11/2022 11:42:31 AM - INFO - global step: 3594, epoch_7, lr: 0.00090, 480/519: Train average loss: 0.333
04/11/2022 11:42:35 AM - INFO - global step: 3604, epoch_7, lr: 0.00090, 490/519: Train average loss: 0.335
04/11/2022 11:42:39 AM - INFO - global step: 3614, epoch_7, lr: 0.00090, 500/519: Train average loss: 0.334
04/11/2022 11:42:43 AM - INFO - global step: 3624, epoch_7, lr: 0.00090, 510/519: Train average loss: 0.335
04/11/2022 11:42:47 AM - INFO - ==========================================================
04/11/2022 11:42:47 AM - INFO - epoch_7: Train set(Aug) miou is: 0.544
04/11/2022 11:42:55 AM - INFO - epoch_7: Valid set average loss is: 0.286
04/11/2022 11:42:55 AM - INFO - epoch_7: Valid set miou is: 0.560
04/11/2022 11:42:55 AM - INFO - ==========================================================
04/11/2022 11:42:59 AM - INFO - global step: 3643, epoch_8, lr: 0.00090, 10/519: Train average loss: 0.341
04/11/2022 11:43:03 AM - INFO - global step: 3653, epoch_8, lr: 0.00090, 20/519: Train average loss: 0.324
04/11/2022 11:43:07 AM - INFO - global step: 3663, epoch_8, lr: 0.00090, 30/519: Train average loss: 0.331
04/11/2022 11:43:12 AM - INFO - global step: 3673, epoch_8, lr: 0.00090, 40/519: Train average loss: 0.330
04/11/2022 11:43:16 AM - INFO - global step: 3683, epoch_8, lr: 0.00090, 50/519: Train average loss: 0.330
04/11/2022 11:43:20 AM - INFO - global step: 3693, epoch_8, lr: 0.00090, 60/519: Train average loss: 0.328
04/11/2022 11:43:24 AM - INFO - global step: 3703, epoch_8, lr: 0.00090, 70/519: Train average loss: 0.326
04/11/2022 11:43:29 AM - INFO - global step: 3713, epoch_8, lr: 0.00090, 80/519: Train average loss: 0.328
04/11/2022 11:43:33 AM - INFO - global step: 3723, epoch_8, lr: 0.00090, 90/519: Train average loss: 0.331
04/11/2022 11:43:37 AM - INFO - global step: 3733, epoch_8, lr: 0.00090, 100/519: Train average loss: 0.331
04/11/2022 11:43:42 AM - INFO - global step: 3743, epoch_8, lr: 0.00090, 110/519: Train average loss: 0.329
04/11/2022 11:43:46 AM - INFO - global step: 3753, epoch_8, lr: 0.00090, 120/519: Train average loss: 0.331
04/11/2022 11:43:50 AM - INFO - global step: 3763, epoch_8, lr: 0.00090, 130/519: Train average loss: 0.330
04/11/2022 11:43:55 AM - INFO - global step: 3773, epoch_8, lr: 0.00090, 140/519: Train average loss: 0.333
04/11/2022 11:43:59 AM - INFO - global step: 3783, epoch_8, lr: 0.00090, 150/519: Train average loss: 0.334
04/11/2022 11:44:03 AM - INFO - global step: 3793, epoch_8, lr: 0.00090, 160/519: Train average loss: 0.335
04/11/2022 11:44:08 AM - INFO - global step: 3803, epoch_8, lr: 0.00090, 170/519: Train average loss: 0.334
04/11/2022 11:44:12 AM - INFO - global step: 3813, epoch_8, lr: 0.00090, 180/519: Train average loss: 0.334
04/11/2022 11:44:17 AM - INFO - global step: 3823, epoch_8, lr: 0.00090, 190/519: Train average loss: 0.336
04/11/2022 11:44:21 AM - INFO - global step: 3833, epoch_8, lr: 0.00090, 200/519: Train average loss: 0.335
04/11/2022 11:44:25 AM - INFO - global step: 3843, epoch_8, lr: 0.00090, 210/519: Train average loss: 0.334
04/11/2022 11:44:30 AM - INFO - global step: 3853, epoch_8, lr: 0.00090, 220/519: Train average loss: 0.331
04/11/2022 11:44:34 AM - INFO - global step: 3863, epoch_8, lr: 0.00090, 230/519: Train average loss: 0.332
04/11/2022 11:44:38 AM - INFO - global step: 3873, epoch_8, lr: 0.00090, 240/519: Train average loss: 0.333
04/11/2022 11:44:43 AM - INFO - global step: 3883, epoch_8, lr: 0.00090, 250/519: Train average loss: 0.333
04/11/2022 11:44:47 AM - INFO - global step: 3893, epoch_8, lr: 0.00090, 260/519: Train average loss: 0.333
04/11/2022 11:44:52 AM - INFO - global step: 3903, epoch_8, lr: 0.00090, 270/519: Train average loss: 0.333
04/11/2022 11:44:56 AM - INFO - global step: 3913, epoch_8, lr: 0.00090, 280/519: Train average loss: 0.333
04/11/2022 11:45:00 AM - INFO - global step: 3923, epoch_8, lr: 0.00090, 290/519: Train average loss: 0.332
04/11/2022 11:45:05 AM - INFO - global step: 3933, epoch_8, lr: 0.00090, 300/519: Train average loss: 0.332
04/11/2022 11:45:09 AM - INFO - global step: 3943, epoch_8, lr: 0.00090, 310/519: Train average loss: 0.332
04/11/2022 11:45:14 AM - INFO - global step: 3953, epoch_8, lr: 0.00090, 320/519: Train average loss: 0.333
04/11/2022 11:45:18 AM - INFO - global step: 3963, epoch_8, lr: 0.00090, 330/519: Train average loss: 0.334
04/11/2022 11:45:23 AM - INFO - global step: 3973, epoch_8, lr: 0.00090, 340/519: Train average loss: 0.333
04/11/2022 11:45:27 AM - INFO - global step: 3983, epoch_8, lr: 0.00090, 350/519: Train average loss: 0.333
04/11/2022 11:45:31 AM - INFO - global step: 3993, epoch_8, lr: 0.00090, 360/519: Train average loss: 0.334
04/11/2022 11:45:36 AM - INFO - global step: 4003, epoch_8, lr: 0.00081, 370/519: Train average loss: 0.334
04/11/2022 11:45:41 AM - INFO - global step: 4013, epoch_8, lr: 0.00081, 380/519: Train average loss: 0.334
04/11/2022 11:45:46 AM - INFO - global step: 4023, epoch_8, lr: 0.00081, 390/519: Train average loss: 0.334
04/11/2022 11:45:51 AM - INFO - global step: 4033, epoch_8, lr: 0.00081, 400/519: Train average loss: 0.335
04/11/2022 11:45:55 AM - INFO - global step: 4043, epoch_8, lr: 0.00081, 410/519: Train average loss: 0.334
04/11/2022 11:45:59 AM - INFO - global step: 4053, epoch_8, lr: 0.00081, 420/519: Train average loss: 0.333
04/11/2022 11:46:04 AM - INFO - global step: 4063, epoch_8, lr: 0.00081, 430/519: Train average loss: 0.334
04/11/2022 11:46:08 AM - INFO - global step: 4073, epoch_8, lr: 0.00081, 440/519: Train average loss: 0.333
04/11/2022 11:46:13 AM - INFO - global step: 4083, epoch_8, lr: 0.00081, 450/519: Train average loss: 0.333
04/11/2022 11:46:17 AM - INFO - global step: 4093, epoch_8, lr: 0.00081, 460/519: Train average loss: 0.332
04/11/2022 11:46:22 AM - INFO - global step: 4103, epoch_8, lr: 0.00081, 470/519: Train average loss: 0.333
04/11/2022 11:46:27 AM - INFO - global step: 4113, epoch_8, lr: 0.00081, 480/519: Train average loss: 0.334
04/11/2022 11:46:31 AM - INFO - global step: 4123, epoch_8, lr: 0.00081, 490/519: Train average loss: 0.333
04/11/2022 11:46:36 AM - INFO - global step: 4133, epoch_8, lr: 0.00081, 500/519: Train average loss: 0.333
04/11/2022 11:46:40 AM - INFO - global step: 4143, epoch_8, lr: 0.00081, 510/519: Train average loss: 0.333
04/11/2022 11:46:44 AM - INFO - ==========================================================
04/11/2022 11:46:44 AM - INFO - epoch_8: Train set(Aug) miou is: 0.545
04/11/2022 11:46:52 AM - INFO - epoch_8: Valid set average loss is: 0.293
04/11/2022 11:46:52 AM - INFO - epoch_8: Valid set miou is: 0.555
04/11/2022 11:46:52 AM - INFO - ==========================================================
04/11/2022 11:46:57 AM - INFO - global step: 4162, epoch_9, lr: 0.00081, 10/519: Train average loss: 0.316
04/11/2022 11:47:01 AM - INFO - global step: 4172, epoch_9, lr: 0.00081, 20/519: Train average loss: 0.312
04/11/2022 11:47:06 AM - INFO - global step: 4182, epoch_9, lr: 0.00081, 30/519: Train average loss: 0.304
04/11/2022 11:47:10 AM - INFO - global step: 4192, epoch_9, lr: 0.00081, 40/519: Train average loss: 0.308
04/11/2022 11:47:15 AM - INFO - global step: 4202, epoch_9, lr: 0.00081, 50/519: Train average loss: 0.308
04/11/2022 11:47:19 AM - INFO - global step: 4212, epoch_9, lr: 0.00081, 60/519: Train average loss: 0.303
04/11/2022 11:47:24 AM - INFO - global step: 4222, epoch_9, lr: 0.00081, 70/519: Train average loss: 0.307
04/11/2022 11:47:29 AM - INFO - global step: 4232, epoch_9, lr: 0.00081, 80/519: Train average loss: 0.313
04/11/2022 11:47:33 AM - INFO - global step: 4242, epoch_9, lr: 0.00081, 90/519: Train average loss: 0.313
04/11/2022 11:47:38 AM - INFO - global step: 4252, epoch_9, lr: 0.00081, 100/519: Train average loss: 0.311
04/11/2022 11:47:42 AM - INFO - global step: 4262, epoch_9, lr: 0.00081, 110/519: Train average loss: 0.314
04/11/2022 11:47:47 AM - INFO - global step: 4272, epoch_9, lr: 0.00081, 120/519: Train average loss: 0.315
04/11/2022 11:47:51 AM - INFO - global step: 4282, epoch_9, lr: 0.00081, 130/519: Train average loss: 0.316
04/11/2022 11:47:56 AM - INFO - global step: 4292, epoch_9, lr: 0.00081, 140/519: Train average loss: 0.316
04/11/2022 11:48:00 AM - INFO - global step: 4302, epoch_9, lr: 0.00081, 150/519: Train average loss: 0.316
04/11/2022 11:48:04 AM - INFO - global step: 4312, epoch_9, lr: 0.00081, 160/519: Train average loss: 0.316
04/11/2022 11:48:09 AM - INFO - global step: 4322, epoch_9, lr: 0.00081, 170/519: Train average loss: 0.315
04/11/2022 11:48:14 AM - INFO - global step: 4332, epoch_9, lr: 0.00081, 180/519: Train average loss: 0.315
04/11/2022 11:48:18 AM - INFO - global step: 4342, epoch_9, lr: 0.00081, 190/519: Train average loss: 0.315
04/11/2022 11:48:22 AM - INFO - global step: 4352, epoch_9, lr: 0.00081, 200/519: Train average loss: 0.315
04/11/2022 11:48:27 AM - INFO - global step: 4362, epoch_9, lr: 0.00081, 210/519: Train average loss: 0.314
04/11/2022 11:48:31 AM - INFO - global step: 4372, epoch_9, lr: 0.00081, 220/519: Train average loss: 0.314
04/11/2022 11:48:36 AM - INFO - global step: 4382, epoch_9, lr: 0.00081, 230/519: Train average loss: 0.316
04/11/2022 11:48:41 AM - INFO - global step: 4392, epoch_9, lr: 0.00081, 240/519: Train average loss: 0.315
04/11/2022 11:48:45 AM - INFO - global step: 4402, epoch_9, lr: 0.00081, 250/519: Train average loss: 0.317
04/11/2022 11:48:50 AM - INFO - global step: 4412, epoch_9, lr: 0.00081, 260/519: Train average loss: 0.319
04/11/2022 11:48:54 AM - INFO - global step: 4422, epoch_9, lr: 0.00081, 270/519: Train average loss: 0.319
04/11/2022 11:48:59 AM - INFO - global step: 4432, epoch_9, lr: 0.00081, 280/519: Train average loss: 0.319
04/11/2022 11:49:03 AM - INFO - global step: 4442, epoch_9, lr: 0.00081, 290/519: Train average loss: 0.318
04/11/2022 11:49:08 AM - INFO - global step: 4452, epoch_9, lr: 0.00081, 300/519: Train average loss: 0.318
04/11/2022 11:49:12 AM - INFO - global step: 4462, epoch_9, lr: 0.00081, 310/519: Train average loss: 0.319
04/11/2022 11:49:16 AM - INFO - global step: 4472, epoch_9, lr: 0.00081, 320/519: Train average loss: 0.320
04/11/2022 11:49:21 AM - INFO - global step: 4482, epoch_9, lr: 0.00081, 330/519: Train average loss: 0.321
04/11/2022 11:49:25 AM - INFO - global step: 4492, epoch_9, lr: 0.00081, 340/519: Train average loss: 0.321
04/11/2022 11:49:30 AM - INFO - global step: 4502, epoch_9, lr: 0.00081, 350/519: Train average loss: 0.321
04/11/2022 11:49:35 AM - INFO - global step: 4512, epoch_9, lr: 0.00081, 360/519: Train average loss: 0.321
04/11/2022 11:49:39 AM - INFO - global step: 4522, epoch_9, lr: 0.00081, 370/519: Train average loss: 0.321
04/11/2022 11:49:43 AM - INFO - global step: 4532, epoch_9, lr: 0.00081, 380/519: Train average loss: 0.322
04/11/2022 11:49:48 AM - INFO - global step: 4542, epoch_9, lr: 0.00081, 390/519: Train average loss: 0.322
04/11/2022 11:49:53 AM - INFO - global step: 4552, epoch_9, lr: 0.00081, 400/519: Train average loss: 0.322
04/11/2022 11:49:57 AM - INFO - global step: 4562, epoch_9, lr: 0.00081, 410/519: Train average loss: 0.322
04/11/2022 11:50:01 AM - INFO - global step: 4572, epoch_9, lr: 0.00081, 420/519: Train average loss: 0.321
04/11/2022 11:50:06 AM - INFO - global step: 4582, epoch_9, lr: 0.00081, 430/519: Train average loss: 0.320
04/11/2022 11:50:11 AM - INFO - global step: 4592, epoch_9, lr: 0.00081, 440/519: Train average loss: 0.320
04/11/2022 11:50:15 AM - INFO - global step: 4602, epoch_9, lr: 0.00081, 450/519: Train average loss: 0.322
04/11/2022 11:50:20 AM - INFO - global step: 4612, epoch_9, lr: 0.00081, 460/519: Train average loss: 0.323
04/11/2022 11:50:24 AM - INFO - global step: 4622, epoch_9, lr: 0.00081, 470/519: Train average loss: 0.322
04/11/2022 11:50:29 AM - INFO - global step: 4632, epoch_9, lr: 0.00081, 480/519: Train average loss: 0.322
04/11/2022 11:50:33 AM - INFO - global step: 4642, epoch_9, lr: 0.00081, 490/519: Train average loss: 0.322
04/11/2022 11:50:38 AM - INFO - global step: 4652, epoch_9, lr: 0.00081, 500/519: Train average loss: 0.321
04/11/2022 11:50:42 AM - INFO - global step: 4662, epoch_9, lr: 0.00081, 510/519: Train average loss: 0.321
04/11/2022 11:50:46 AM - INFO - ==========================================================
04/11/2022 11:50:46 AM - INFO - epoch_9: Train set(Aug) miou is: 0.561
04/11/2022 11:50:54 AM - INFO - epoch_9: Valid set average loss is: 0.284
04/11/2022 11:50:54 AM - INFO - epoch_9: Valid set miou is: 0.595
04/11/2022 11:50:54 AM - INFO - ==========================================================
04/11/2022 11:50:59 AM - INFO - global step: 4681, epoch_10, lr: 0.00081, 10/519: Train average loss: 0.276
04/11/2022 11:51:03 AM - INFO - global step: 4691, epoch_10, lr: 0.00081, 20/519: Train average loss: 0.291
04/11/2022 11:51:08 AM - INFO - global step: 4701, epoch_10, lr: 0.00081, 30/519: Train average loss: 0.298
04/11/2022 11:51:12 AM - INFO - global step: 4711, epoch_10, lr: 0.00081, 40/519: Train average loss: 0.297
04/11/2022 11:51:16 AM - INFO - global step: 4721, epoch_10, lr: 0.00081, 50/519: Train average loss: 0.303
04/11/2022 11:51:21 AM - INFO - global step: 4731, epoch_10, lr: 0.00081, 60/519: Train average loss: 0.309
04/11/2022 11:51:25 AM - INFO - global step: 4741, epoch_10, lr: 0.00081, 70/519: Train average loss: 0.307
04/11/2022 11:51:30 AM - INFO - global step: 4751, epoch_10, lr: 0.00081, 80/519: Train average loss: 0.309
04/11/2022 11:51:34 AM - INFO - global step: 4761, epoch_10, lr: 0.00081, 90/519: Train average loss: 0.310
04/11/2022 11:51:38 AM - INFO - global step: 4771, epoch_10, lr: 0.00081, 100/519: Train average loss: 0.310
04/11/2022 11:51:43 AM - INFO - global step: 4781, epoch_10, lr: 0.00081, 110/519: Train average loss: 0.311
04/11/2022 11:51:47 AM - INFO - global step: 4791, epoch_10, lr: 0.00081, 120/519: Train average loss: 0.310
04/11/2022 11:51:52 AM - INFO - global step: 4801, epoch_10, lr: 0.00081, 130/519: Train average loss: 0.312
04/11/2022 11:51:56 AM - INFO - global step: 4811, epoch_10, lr: 0.00081, 140/519: Train average loss: 0.312
04/11/2022 11:52:00 AM - INFO - global step: 4821, epoch_10, lr: 0.00081, 150/519: Train average loss: 0.312
04/11/2022 11:52:05 AM - INFO - global step: 4831, epoch_10, lr: 0.00081, 160/519: Train average loss: 0.313
04/11/2022 11:52:09 AM - INFO - global step: 4841, epoch_10, lr: 0.00081, 170/519: Train average loss: 0.314
04/11/2022 11:52:14 AM - INFO - global step: 4851, epoch_10, lr: 0.00081, 180/519: Train average loss: 0.317
04/11/2022 11:52:18 AM - INFO - global step: 4861, epoch_10, lr: 0.00081, 190/519: Train average loss: 0.318
04/11/2022 11:52:23 AM - INFO - global step: 4871, epoch_10, lr: 0.00081, 200/519: Train average loss: 0.318
04/11/2022 11:52:27 AM - INFO - global step: 4881, epoch_10, lr: 0.00081, 210/519: Train average loss: 0.318
04/11/2022 11:52:32 AM - INFO - global step: 4891, epoch_10, lr: 0.00081, 220/519: Train average loss: 0.318
04/11/2022 11:52:36 AM - INFO - global step: 4901, epoch_10, lr: 0.00081, 230/519: Train average loss: 0.316
04/11/2022 11:52:40 AM - INFO - global step: 4911, epoch_10, lr: 0.00081, 240/519: Train average loss: 0.315
04/11/2022 11:52:45 AM - INFO - global step: 4921, epoch_10, lr: 0.00081, 250/519: Train average loss: 0.314
04/11/2022 11:52:49 AM - INFO - global step: 4931, epoch_10, lr: 0.00081, 260/519: Train average loss: 0.313
04/11/2022 11:52:54 AM - INFO - global step: 4941, epoch_10, lr: 0.00081, 270/519: Train average loss: 0.315
04/11/2022 11:52:58 AM - INFO - global step: 4951, epoch_10, lr: 0.00081, 280/519: Train average loss: 0.316
04/11/2022 11:53:03 AM - INFO - global step: 4961, epoch_10, lr: 0.00081, 290/519: Train average loss: 0.316
04/11/2022 11:53:08 AM - INFO - global step: 4971, epoch_10, lr: 0.00081, 300/519: Train average loss: 0.315
04/11/2022 11:53:12 AM - INFO - global step: 4981, epoch_10, lr: 0.00081, 310/519: Train average loss: 0.316
04/11/2022 11:53:16 AM - INFO - global step: 4991, epoch_10, lr: 0.00081, 320/519: Train average loss: 0.316
04/11/2022 11:53:21 AM - INFO - global step: 5001, epoch_10, lr: 0.00081, 330/519: Train average loss: 0.315
04/11/2022 11:53:25 AM - INFO - global step: 5011, epoch_10, lr: 0.00081, 340/519: Train average loss: 0.314
04/11/2022 11:53:30 AM - INFO - global step: 5021, epoch_10, lr: 0.00081, 350/519: Train average loss: 0.314
04/11/2022 11:53:34 AM - INFO - global step: 5031, epoch_10, lr: 0.00081, 360/519: Train average loss: 0.314
04/11/2022 11:53:38 AM - INFO - global step: 5041, epoch_10, lr: 0.00081, 370/519: Train average loss: 0.312
04/11/2022 11:53:43 AM - INFO - global step: 5051, epoch_10, lr: 0.00081, 380/519: Train average loss: 0.312
04/11/2022 11:53:47 AM - INFO - global step: 5061, epoch_10, lr: 0.00081, 390/519: Train average loss: 0.312
04/11/2022 11:53:52 AM - INFO - global step: 5071, epoch_10, lr: 0.00081, 400/519: Train average loss: 0.312
04/11/2022 11:53:56 AM - INFO - global step: 5081, epoch_10, lr: 0.00081, 410/519: Train average loss: 0.312
04/11/2022 11:54:01 AM - INFO - global step: 5091, epoch_10, lr: 0.00081, 420/519: Train average loss: 0.312
04/11/2022 11:54:05 AM - INFO - global step: 5101, epoch_10, lr: 0.00081, 430/519: Train average loss: 0.312
04/11/2022 11:54:10 AM - INFO - global step: 5111, epoch_10, lr: 0.00081, 440/519: Train average loss: 0.311
04/11/2022 11:54:14 AM - INFO - global step: 5121, epoch_10, lr: 0.00081, 450/519: Train average loss: 0.312
04/11/2022 11:54:18 AM - INFO - global step: 5131, epoch_10, lr: 0.00081, 460/519: Train average loss: 0.312
04/11/2022 11:54:23 AM - INFO - global step: 5141, epoch_10, lr: 0.00081, 470/519: Train average loss: 0.313
04/11/2022 11:54:27 AM - INFO - global step: 5151, epoch_10, lr: 0.00081, 480/519: Train average loss: 0.314
04/11/2022 11:54:32 AM - INFO - global step: 5161, epoch_10, lr: 0.00081, 490/519: Train average loss: 0.315
04/11/2022 11:54:36 AM - INFO - global step: 5171, epoch_10, lr: 0.00081, 500/519: Train average loss: 0.315
04/11/2022 11:54:41 AM - INFO - global step: 5181, epoch_10, lr: 0.00081, 510/519: Train average loss: 0.316
04/11/2022 11:54:44 AM - INFO - ==========================================================
04/11/2022 11:54:44 AM - INFO - epoch_10: Train set(Aug) miou is: 0.563
04/11/2022 11:54:52 AM - INFO - epoch_10: Valid set average loss is: 0.279
04/11/2022 11:54:52 AM - INFO - epoch_10: Valid set miou is: 0.579
04/11/2022 11:54:52 AM - INFO - ==========================================================
04/11/2022 11:54:57 AM - INFO - global step: 5200, epoch_11, lr: 0.00081, 10/519: Train average loss: 0.299
04/11/2022 11:55:01 AM - INFO - global step: 5210, epoch_11, lr: 0.00081, 20/519: Train average loss: 0.301
04/11/2022 11:55:06 AM - INFO - global step: 5220, epoch_11, lr: 0.00081, 30/519: Train average loss: 0.305
04/11/2022 11:55:10 AM - INFO - global step: 5230, epoch_11, lr: 0.00081, 40/519: Train average loss: 0.309
04/11/2022 11:55:15 AM - INFO - global step: 5240, epoch_11, lr: 0.00081, 50/519: Train average loss: 0.311
04/11/2022 11:55:19 AM - INFO - global step: 5250, epoch_11, lr: 0.00081, 60/519: Train average loss: 0.307
04/11/2022 11:55:24 AM - INFO - global step: 5260, epoch_11, lr: 0.00081, 70/519: Train average loss: 0.307
04/11/2022 11:55:28 AM - INFO - global step: 5270, epoch_11, lr: 0.00081, 80/519: Train average loss: 0.308
04/11/2022 11:55:32 AM - INFO - global step: 5280, epoch_11, lr: 0.00081, 90/519: Train average loss: 0.306
04/11/2022 11:55:37 AM - INFO - global step: 5290, epoch_11, lr: 0.00081, 100/519: Train average loss: 0.305
04/11/2022 11:55:41 AM - INFO - global step: 5300, epoch_11, lr: 0.00081, 110/519: Train average loss: 0.305
